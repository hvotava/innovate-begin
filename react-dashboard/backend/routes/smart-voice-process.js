const { ConversationManager } = require('./ai-conversation');

// Smart voice processing with conversation flow
async function smartVoiceProcess(req, res) {
  console.log('ğŸ§  SMART Voice processing');
  console.log('ğŸ“ Request body:', req.body);
  
  const { RecordingUrl, CallSid, RecordingDuration } = req.body;
  
  // Check if we have a recording
  if (!RecordingUrl) {
    console.log('âŒ No recording URL provided');
    const fallbackTwiml = `<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <Say language="cs-CZ" rate="0.9" voice="Google.cs-CZ-Standard-A">
        OmlouvÃ¡m se, nerozumÄ›l jsem. MÅ¯Å¾ete to zopakovat?
    </Say>
    <Record 
        timeout="8"
        maxLength="30"
        action="https://lecture-final-production.up.railway.app/api/twilio/voice/process"
        method="POST"
        transcribe="true"
        transcribeCallback="https://lecture-final-production.up.railway.app/api/twilio/voice/transcribe"
    />
</Response>`;
    
    res.set('Content-Type', 'application/xml');
    return res.send(fallbackTwiml);
  }
  
  console.log(`ğŸµ Processing ${RecordingDuration}s recording: ${RecordingUrl}`);
  
  // For now, generate next question based on conversation flow
  // This could be enhanced with actual transcription processing
  const nextQuestionTwiml = `<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <Say language="cs-CZ" rate="0.9" voice="Google.cs-CZ-Standard-A">
        DÄ›kuji za vaÅ¡i odpovÄ›Ä. PokraÄujme dalÅ¡Ã­ otÃ¡zkou.
    </Say>
    <Say language="cs-CZ" rate="0.8" voice="Google.cs-CZ-Standard-A">
        NynÃ­ mi Å™eknÄ›te o vaÅ¡Ã­ prÃ¡ci nebo studiu v angliÄtinÄ›.
    </Say>
    <Record 
        timeout="8"
        maxLength="30"
        finishOnKey="#"
        action="https://lecture-final-production.up.railway.app/api/twilio/voice/process"
        method="POST"
        transcribe="true"
        transcribeCallback="https://lecture-final-production.up.railway.app/api/twilio/voice/transcribe"
    />
    <Say language="cs-CZ" rate="0.9" voice="Google.cs-CZ-Standard-A">
        StisknÄ›te mÅ™Ã­Å¾ku kdyÅ¾ dokonÄÃ­te odpovÄ›Ä.
    </Say>
</Response>`;

  console.log('âœ… SMART TwiML with shorter timeout and finish key');
  res.set('Content-Type', 'application/xml');
  res.send(nextQuestionTwiml);
}

// Enhanced transcription processor
async function smartTranscribeProcess(req, res) {
  console.log('ğŸ¯ SMART Transcription processing');
  console.log('ğŸ¯ CallSid:', req.body.CallSid);
  console.log('ğŸ“„ TranscriptionText:', req.body.TranscriptionText);
  console.log('ğŸ“Š TranscriptionStatus:', req.body.TranscriptionStatus);
  
  const transcribedText = req.body.TranscriptionText;
  
  if (transcribedText && req.body.TranscriptionStatus === 'completed') {
    console.log(`ğŸ’¬ User said: "${transcribedText}"`);
    
    try {
      // Process with AI conversation manager
      const response = await ConversationManager.processUserResponse(
        transcribedText, 
        'introduction', // This would be dynamic based on conversation state
        req.body.From
      );
      
      console.log('ğŸ§  AI Analysis:', response);
      
      // Here you could update user progress in database
      // or trigger next question generation
      
    } catch (error) {
      console.error('âŒ Transcription processing error:', error.message);
    }
  }
  
  res.send('OK');
}

module.exports = { smartVoiceProcess, smartTranscribeProcess };
